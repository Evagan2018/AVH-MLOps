# This YAML file is used to test a custom Docker image with the necessary tools and dependencies for an ML project
# It contains a job that runs tests on a Ubuntu machine using the custom Docker image

name: Licensed Docker Image - Test

on:
  # Trigger the workflow when a workflow run is completed
  workflow_run:
    workflows: ["Licensed Docker Image - Build and Push"]
    types:
      - completed
  # Trigger the workflow manually
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}/avh-mlops

jobs:

  check-docker-image:
    runs-on: ubuntu-latest
    outputs:
      image-exists: ${{ steps.check.outputs.exists }}
      repo-slug: ${{ steps.slug.outputs.repo_slug }}
    steps:
      - name: Derive lowercase repo slug
        id: slug
        run: echo "repo_slug=$(echo '${{ github.repository }}' | tr '[:upper:]' '[:lower:]')" >> $GITHUB_OUTPUT

      - name: Check if Docker image exists
        id: check
        run: |
          if docker manifest inspect ghcr.io/$(echo '${{ github.repository }}' | tr '[:upper:]' '[:lower:]')/arm-mlops-docker-licensed:latest > /dev/null 2>&1; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Diagnosis
        run: |
          echo "Repository Slug: ${{ steps.slug.outputs.repo_slug }}"
          echo "Image Exists: ${{ steps.check.outputs.exists }}"

  run_test:
    needs: check-docker-image
    runs-on: ubuntu-latest

    container:
      # Use the custom Docker image with the necessary tools and dependencies
      image: ghcr.io/${{ needs.check-docker-image.outputs.repo-slug }}/arm-mlops-docker-licensed:latest
      credentials:
        # Set the Docker image credentials using the actor and a GitHub token
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    steps:
      - name: Checkout repository
        # Check out the repository containing the ML project
        uses: actions/checkout@v5

      # Diagnostic steps to understand the workspace and vcpkg setup starting here
      - name: Debug workspace (robust)
        run: |
          # Turn off 'exit on error' that GitHub's sh enables, so optional probes won't kill the step
          set +e

          # Safely show common env vars (use defaults to avoid 'unset' crashes)
          printf 'SHELL=%s\n' "${SHELL:-<unset>}"
          printf 'GITHUB_WORKSPACE=%s\n' "${GITHUB_WORKSPACE:-<unset>}"
          printf 'github.workspace=%s\n' "${{ github.workspace }}"
          printf 'PWD=%s\n' "$(pwd)"
          printf 'VCPKG_ROOT=%s\n' "${VCPKG_ROOT:-<unset>}"

          echo "Directory structure (3 levels):"
          if command -v tree >/dev/null 2>&1; then
            tree -L 3
          else
            echo "(tree not installed; using find)"
            # List dirs/files up to depth 3
            find . -maxdepth 3 -printf '%y %p\n' | sort
          fi

          echo "Contents of root:"
          ls -la

          echo "Looking for vcpkg manifest files at repo root:"
          ls -la vcpkg-configuration.json vcpkg-artifacts.json 2>/dev/null || echo "No vcpkg artifact manifests at root"

          for d in tools/ci docker_base docker_licensed ; do
            if [ -d "$d" ]; then
              echo "== $d =="
              ls -la "$d"
            fi
          done

      # Diagnostic steps to understand the workspace and vcpkg setup ending here

      - name: Use vcpkg to install tools
        working-directory: docker_base
        run: |
          vcpkg activate --downloads-root="${GITHUB_WORKSPACE}/.vcpkg-downloads" --json="${GITHUB_WORKSPACE}/env.json"

      - name: Export vcpkg environment for subsequent steps (with debug)
        shell: sh
        run: |
          set -eu

          # 1) Sanity: show we have the JSON
          echo "GITHUB_WORKSPACE=${GITHUB_WORKSPACE:-<unset>}"
          echo "GITHUB_ENV=${GITHUB_ENV:-<unset>}"
          ls -l "$GITHUB_WORKSPACE/env.json" || { echo "env.json missing"; exit 1; }

          # 2) Generate shell exports from env.json to a file
          python3 - "$GITHUB_WORKSPACE/env.json" > exports.sh <<'PY'
      import json, os, sys, shlex
      p = sys.argv[1]
      data = json.load(open(p))
      env = data.get("environment", {})

      # Merge PATH so we keep the current PATH at the end (useful for this debug step)
      cur_path = os.environ.get("PATH","")
      if "PATH" in env:
          env["PATH"] = env["PATH"] + (os.pathsep + cur_path if cur_path else "")

      # Print export commands for POSIX sh
      for k, v in env.items():
          # Avoid newlines in values
          v = v.replace("\n", " ")
          print(f'export {k}={shlex.quote(v)}')
      PY

          echo "::group::Preview of exports.sh"
          head -n 50 exports.sh || true
          echo "::endgroup::"

          # 3) Append KEY=VALUE (without 'export ') to $GITHUB_ENV for LATER steps
          #    Also print what we append (trimmed for readability)
          echo "::group::Appending to \$GITHUB_ENV"
          sed 's/^export //' exports.sh | tee -a "$GITHUB_ENV" | sed -n '1,20p'
          echo "(…truncated if many vars…)"
          echo "::endgroup::"

          # 4) For diagnosis ONLY: source the exports in THIS step and check cbuild
          #    (This does not persist to later steps; those will read $GITHUB_ENV.)
          . ./exports.sh

          echo "::group::PATH after sourcing (this step only)"
          echo "$PATH"
          echo "::endgroup::"

          echo "::group::Locate cbuild (this step only)"
          if command -v cbuild >/dev/null 2>&1; then
            echo "cbuild found at: $(command -v cbuild)"
            ls -l "$(command -v cbuild)" || true
            dir="$(dirname "$(command -v cbuild)")"
            echo "Listing directory: $dir"
            ls -la "$dir" || true
          else
            echo "cbuild NOT found even after sourcing exports.sh"
          fi
          echo "::endgroup::"


          


      - name: Test cbuild version
        # Test if the armclang command is working in the Docker container
        run: |
          cbuild --version
 

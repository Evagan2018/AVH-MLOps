# This YAML file is used to test a custom Docker image with the necessary tools and dependencies for an ML project
# It contains a job that runs tests on a Ubuntu machine using the custom Docker image

name: Licensed Docker Image - Test

on:
  # Trigger the workflow when a workflow run is completed
  workflow_run:
    workflows: ["Licensed Docker Image - Build and Push"]
    types:
      - completed
  # Trigger the workflow manually
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}/avh-mlops

jobs:

  check-docker-image:
    runs-on: ubuntu-latest
    outputs:
      image-exists: ${{ steps.check.outputs.exists }}
      repo-slug: ${{ steps.slug.outputs.repo_slug }}
    steps:
      - name: Derive lowercase repo slug
        id: slug
        run: echo "repo_slug=$(echo '${{ github.repository }}' | tr '[:upper:]' '[:lower:]')" >> $GITHUB_OUTPUT

      - name: Check if Docker image exists
        id: check
        run: |
          if docker manifest inspect ghcr.io/$(echo '${{ github.repository }}' | tr '[:upper:]' '[:lower:]')/arm-mlops-docker-licensed:latest > /dev/null 2>&1; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Diagnosis
        run: |
          echo "Repository Slug: ${{ steps.slug.outputs.repo_slug }}"
          echo "Image Exists: ${{ steps.check.outputs.exists }}"

  run_test:
    needs: check-docker-image
    runs-on: ubuntu-latest

    container:
      # Use the custom Docker image with the necessary tools and dependencies
      image: ghcr.io/${{ needs.check-docker-image.outputs.repo-slug }}/arm-mlops-docker-licensed:latest
      credentials:
        # Set the Docker image credentials using the actor and a GitHub token
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    steps:
      - name: Checkout repository
        # Check out the repository containing the ML project
        uses: actions/checkout@v5

      # === Diagnostic steps to understand the workspace and vcpkg setup starting here ===

      - name: Diagnosis 1
        # Show the globals
        run: |
          echo "GitHub Workspace :" ${GITHUB_WORKSPACE}
          echo "GitHub Path      :" ${GITHUB_PATH}
          echo "Content env.json :" $(cat ${GITHUB_WORKSPACE}/env.json)

      - name: Debug workspace (robust)
        run: |
          # Turn off 'exit on error' that GitHub's sh enables, so optional probes won't kill the step
          set +e

          # Safely show common env vars (use defaults to avoid 'unset' crashes)
          printf 'SHELL=%s\n' "${SHELL:-<unset>}"
          printf 'GITHUB_WORKSPACE=%s\n' "${GITHUB_WORKSPACE:-<unset>}"
          printf 'github.workspace=%s\n' "${{ github.workspace }}"
          printf 'PWD=%s\n' "$(pwd)"
          printf 'VCPKG_ROOT=%s\n' "${VCPKG_ROOT:-<unset>}"

          echo "Directory structure (3 levels):"
          if command -v tree >/dev/null 2>&1; then
            tree -L 3
          else
            echo "(tree not installed; using find)"
            # List dirs/files up to depth 3
            find . -maxdepth 3 -printf '%y %p\n' | sort
          fi

          echo "Contents of root:"
          ls -la

          echo "Looking for vcpkg manifest files at repo root:"
          ls -la vcpkg-configuration.json vcpkg-artifacts.json 2>/dev/null || echo "No vcpkg artifact manifests at root"

          for d in tools/ci docker_base docker_licensed ; do
            if [ -d "$d" ]; then
              echo "== $d =="
              ls -la "$d"
            fi
          done

      # === Diagnostic steps to understand the workspace and vcpkg setup ending here ===

      - name: Activate vcpkg tools (writes env.json)
        working-directory: docker_base
        run: |
          vcpkg activate --downloads-root="${GITHUB_WORKSPACE}/.vcpkg-downloads" \
                        --json="${GITHUB_WORKSPACE}/env.json"

      - name: Add vcpkg tool paths to $GITHUB_PATH
        shell: bash
        run: |
          set -euo pipefail
          P="${GITHUB_WORKSPACE}/env.json"
          python3 - "$P" "$GITHUB_PATH" <<'PY'
          import json, os, sys
          p, ghp = sys.argv[1], sys.argv[2]
          d = json.load(open(p))
          paths = []
          vars = d.get("variables", {})
          if "PATH" in vars and vars["PATH"]:
              paths += vars["PATH"].split(os.pathsep)
          pth = d.get("paths", {})
          if "PATH" in pth and isinstance(pth["PATH"], list):
              paths += pth["PATH"]
          seen=set(); uniq=[]
          for x in paths:
              if x and x not in seen:
                  seen.add(x); uniq.append(x)
          with open(ghp, "a") as out:
              for x in uniq:
                  if os.path.isdir(x):
                      out.write(x + "\n")
          PY

      - name: Test cbuild version
        # Test if the cbuild command is working in the Docker container
        run: |
          cbuild --version

      - name: Diagnosis 2
        # Show the globals
        run: |
          echo "GitHub Workspace :" ${GITHUB_WORKSPACE}
          echo "GitHub Path      :" ${GITHUB_PATH}
          echo "Content env.json :" $(cat ${GITHUB_WORKSPACE}/env.json)
